{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Testing and Training Sets from Features Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "features_df = pd.read_csv(\"data/features_with_shuttles.csv\")\n",
    "features = ['Total Housing Units','Percent Asian', 'Percent White', 'Percent Black','Median Year Structure Built',\n",
    "           'Number Stops','Year', 'Percent Native', 'Median Year Moved In', 'Median rent burden', \"Percent with Bachelor's degree\",\n",
    "           'Neighbors Mean', \"Evictions per units\", \"geometry\"]\n",
    "\n",
    "features_df_keep = features_df.loc[:, features_df.columns.isin(features)]\n",
    "#features_df_keep.to_csv('data/exploratory_data.csv', index=False)\n",
    "\n",
    "X = features_df_keep.loc[:, features_df_keep.columns != 'Evictions per units']\n",
    "y = features_df_keep.loc[:,'Evictions per units']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize features data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(data, mean_df, std_df):\n",
    "    '''\n",
    "    Input:\n",
    "      data (data frame): contains only numeric columns\n",
    "    Output:\n",
    "      data frame, the same data, except each column is standardized \n",
    "      to have 0-mean and unit variance\n",
    "    '''\n",
    "    normalized_data=(data-mean_df.mean())/std_df.std()\n",
    "\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize_columns(data, mean_df, std_df):\n",
    "    unnormalized_data=(data*std_df.std())+mean_df.mean()\n",
    "\n",
    "    return unnormalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_Xtrain = normalize_columns(X_train, X_train, X_train)\n",
    "normal_Ytrain = normalize_columns(y_train, y_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Lasso for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0027002700279999997"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "cv_alphas = np.linspace(1e-12, 1, 10000)\n",
    "\n",
    "lasso = LassoCV(alphas=cv_alphas, normalize=False, max_iter=1e6).fit(normal_Xtrain, normal_Ytrain)\n",
    "lcv_alpha_normal = lasso.alpha_\n",
    "lcv_alpha_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_fit = Lasso(alpha=lcv_alpha_normal).fit(normal_Xtrain, normal_Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.41642350e-01,  3.19665882e-04, -5.29020378e-02,  2.47644648e-02,\n",
       "        1.05296817e-01,  7.50270850e-02, -3.11524474e-01, -7.57546772e-01,\n",
       "       -6.50045591e-01, -4.65085589e-03,  1.30944448e-01,  8.43031462e-04,\n",
       "       -5.23492759e-02])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcoefficients = lasso_fit.coef_\n",
    "lcoefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Percent White', -0.7575467724814027),\n",
       "             ('Percent Asian', -0.6500455906340852),\n",
       "             ('Percent Black', -0.311524474498424),\n",
       "             ('Total Housing Units', -0.24164234956267178),\n",
       "             ('Median Year Structure Built', -0.05290203777362707),\n",
       "             ('geometry', -0.052349275921483085),\n",
       "             ('Percent Native', -0.004650855893180121),\n",
       "             ('Year', 0.0003196658819148618),\n",
       "             ('Number Stops', 0.0008430314615542158),\n",
       "             ('Median Year Moved In', 0.024764464828799376),\n",
       "             ('Median rent burden', 0.07502708497580984),\n",
       "             (\"Percent with Bachelor's degree\", 0.10529681678515172),\n",
       "             ('Neighbors Mean', 0.1309444479110688)])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "lasso_coef_dict = OrderedDict()\n",
    "for coef, feature in zip(lasso_fit.coef_, normal_Xtrain.columns):\n",
    "    lasso_coef_dict[feature] = coef\n",
    "sorted_coefs_lasso = OrderedDict(sorted(lasso_coef_dict.items(), key=lambda t: t[1]))\n",
    "sorted_coefs_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(sorted_coefs_lasso.keys(), sorted_coefs_lasso.values())\n",
    "\n",
    "plt.xticks(list(sorted_coefs_lasso.keys()), rotation='vertical', fontsize=10)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Housing Units</th>\n",
       "      <th>Median Year Structure Built</th>\n",
       "      <th>Median Year Moved In</th>\n",
       "      <th>Percent with Bachelor's degree</th>\n",
       "      <th>Median rent burden</th>\n",
       "      <th>Percent Black</th>\n",
       "      <th>Percent White</th>\n",
       "      <th>Percent Asian</th>\n",
       "      <th>Neighbors Mean</th>\n",
       "      <th>Number Stops</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2571.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>25.3</td>\n",
       "      <td>0.067026</td>\n",
       "      <td>0.655027</td>\n",
       "      <td>0.252637</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>2662.0</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.051556</td>\n",
       "      <td>0.686578</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>1446.0</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.222905</td>\n",
       "      <td>0.183897</td>\n",
       "      <td>0.554189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2672.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.047679</td>\n",
       "      <td>0.753477</td>\n",
       "      <td>0.111071</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>3425.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2136.0</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.037752</td>\n",
       "      <td>0.670880</td>\n",
       "      <td>0.163645</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Total Housing Units  Median Year Structure Built  Median Year Moved In  \\\n",
       "117               2571.0                       1949.0                2011.0   \n",
       "827               2662.0                       1945.0                2010.0   \n",
       "380               1446.0                       1945.0                2002.0   \n",
       "176               2672.0                       1939.0                2007.0   \n",
       "223               3425.0                       1939.0                2010.0   \n",
       "\n",
       "     Percent with Bachelor's degree  Median rent burden  Percent Black  \\\n",
       "117                          1531.0                25.3       0.067026   \n",
       "827                             6.5                21.0       0.051556   \n",
       "380                            11.8                34.6       0.222905   \n",
       "176                             6.0                24.6       0.047679   \n",
       "223                          2136.0                23.7       0.037752   \n",
       "\n",
       "     Percent White  Percent Asian  Neighbors Mean  Number Stops  geometry  \n",
       "117       0.655027       0.252637             2.0             8       0.0  \n",
       "827       0.686578       0.150400             4.0            38       0.0  \n",
       "380       0.183897       0.554189             0.0            20       0.0  \n",
       "176       0.753477       0.111071             6.0            15       0.0  \n",
       "223       0.670880       0.163645             5.0             6       0.0  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the new features dataframe without the features lasso removed into train test \n",
    "selected_features = features_df_keep.loc[:, ~(features_df_keep.columns.isin(['Percent Native', 'Year']))]\n",
    "\n",
    "X_l = selected_features.loc[:, selected_features.columns != 'Evictions per units']\n",
    "y_l = selected_features.loc[:,'Evictions per units']\n",
    "X_ltrain, X_ltest, y_ltrain, y_ltest = train_test_split(X_l, y_l, test_size = 0.20)\n",
    "X_ltrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the new training data \n",
    "normal_X_ltrain = normalize_columns(X_ltrain, X_ltrain, X_ltrain)\n",
    "normal_y_ltrain = normalize_columns(y_ltrain, y_ltrain, y_ltrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "n_dict = {\"n_neighbors\": [34, 36, 38, 40, 42, 44, 46, 48, 50]} \n",
    "\n",
    "gsearch = GridSearchCV(estimator=KNeighborsRegressor(), param_grid=n_dict, cv= 10)\n",
    "\n",
    "gsearch_search_fit = gsearch.fit(normal_X_ltrain, normal_y_ltrain)\n",
    "\n",
    "optimal_n_neighbors = gsearch_search_fit.best_params_['n_neighbors']\n",
    "print(optimal_n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 4.939542940997624e-07\n",
      "mae: 0.00045495620315988444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "kn_regressor = KNeighborsRegressor(n_neighbors=optimal_n_neighbors)\n",
    "kn_regressor_fit = kn_regressor.fit(normal_X_ltrain, normal_y_ltrain)\n",
    "normal_y_pred_train = kn_regressor.predict(normal_X_ltrain)\n",
    "\n",
    "y_pred_train = unnormalize_columns(normal_y_pred_train, y_ltrain, y_ltrain)\n",
    "\n",
    "\n",
    "train_mse = mean_squared_error(y_pred_train, y_ltrain)\n",
    "train_mae = mean_absolute_error(y_pred_train, y_ltrain)\n",
    "print('mse:', train_mse)\n",
    "print('mae:', train_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 8.010510690914147e-07\n",
      "mae: 0.0005222515445303953\n"
     ]
    }
   ],
   "source": [
    "normal_X_test = normalize_columns(X_ltest, X_ltrain, X_ltrain)\n",
    "normal_y_pred_test = kn_regressor.predict(normal_X_test)\n",
    "\n",
    "y_pred_test = unnormalize_columns(normal_y_pred_test, y_ltrain, y_ltrain)\n",
    "test_mse = mean_squared_error(y_pred_test, y_ltest)\n",
    "test_mae = mean_absolute_error(y_pred_test, y_ltest)\n",
    "print('mse:', test_mse)\n",
    "print('mae:', test_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 288 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-cc5284281438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgsearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_dict2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgsearch_search_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_X_ltrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormal_y_ltrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0moptimal_forest_params2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgsearch_search_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    638\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    639\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 640\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[0;32m--> 316\u001b[0;31m                                             random_state=random_state)\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0msub\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \"\"\"\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         estimator.set_params(**dict((p, getattr(self, p))\n\u001b[1;32m    127\u001b[0m                                     for p in self.estimator_params))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mparams_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# quick sanity check of the parameters of the clone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     \u001b[0;31m# if the parameter is deprecated, don't show it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/warnings.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *exc_info)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_entered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot exit %r without entering first\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_dict2 = {\"n_estimators\": [30, 50, 100, 130],\n",
    "             \"max_depth\": [350, 400, 450, 500],\n",
    "             \"min_samples_split\": [4, 8, 12],\n",
    "             \"min_samples_leaf\": [2, 5],\n",
    "             \"max_features\": [\"auto\", \"log2\", None]}\n",
    "\n",
    "gsearch = GridSearchCV(estimator=RandomForestRegressor(), param_grid=param_dict2, cv=10, verbose=1)\n",
    "\n",
    "gsearch_search_fit = gsearch.fit(normal_X_ltrain, normal_y_ltrain)\n",
    "\n",
    "optimal_forest_params2 = gsearch_search_fit.best_params_\n",
    "print(optimal_forest_params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_forest_params2 = {'max_depth': 450, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 130}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.7290938575757324\n",
      "Test Score:  0.13624736115416547\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_tree = RandomForestRegressor(max_depth= 450, max_features= optimal_forest_params2['max_features'], \n",
    "                                min_samples_leaf= optimal_forest_params2['min_samples_leaf'], min_samples_split= optimal_forest_params2['min_samples_split'], \n",
    "                                 n_estimators= optimal_forest_params2['n_estimators'])\n",
    "rf_tree_fit = rf_tree.fit(X_ltrain, y_ltrain)\n",
    "\n",
    "rf_train_score = rf_tree.score(X_ltrain, y_ltrain)\n",
    "rf_test_score = rf_tree.score(X_ltest, y_ltest)\n",
    "\n",
    "\n",
    "print('Train Score: ', rf_train_score)\n",
    "\n",
    "print('Test Score: ', rf_test_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized alpha 3.4035\n",
      "training mse 4.69771239358862e-07\n",
      "test mse 6.661549302495166e-07\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV, ridge\n",
    "cv_alphas = np.linspace(0.0001, 100, 1000) #consider changing these\n",
    "\n",
    "ridgeCV = RidgeCV(cv_alphas, normalize=False, scoring='neg_mean_squared_error').fit(normal_X_ltrain, normal_y_ltrain)\n",
    "rcv_alpha = ridgeCV.alpha_\n",
    "\n",
    "ridge_alpha = ridge.Ridge(alpha=rcv_alpha).fit(normal_X_ltrain, normal_y_ltrain)\n",
    "\n",
    "\n",
    "y_pred_normal_train = ridge_alpha.predict(normal_X_ltrain)\n",
    "y_pred_train = unnormalize_columns(y_pred_normal_train, y_ltrain, y_ltrain)\n",
    "\n",
    "train_mse = mean_squared_error(y_pred_train, y_ltrain) #unstandardized\n",
    "\n",
    "#test error\n",
    "normal_X_ltest = normalize_columns(X_ltest, X_ltrain, X_ltrain)\n",
    "y_pred_normal_test = ridge_alpha.predict(normal_X_ltest)\n",
    "y_pred_test = unnormalize_columns(y_pred_normal_test, y_ltrain, y_ltrain)\n",
    "\n",
    "test_mse = mean_squared_error(y_pred_test, y_ltest) #unstandardized\n",
    "\n",
    "                                     \n",
    "print(\"normalized alpha\", rcv_alpha)\n",
    "print(\"training mse\", train_mse)\n",
    "print(\"test mse\", test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "665/665 [==============================] - 0s 501us/step - loss: 1.0055\n",
      "Epoch 2/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.9731\n",
      "Epoch 3/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.9530\n",
      "Epoch 4/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.9375\n",
      "Epoch 5/1000\n",
      "665/665 [==============================] - 0s 80us/step - loss: 0.9262\n",
      "Epoch 6/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.9165\n",
      "Epoch 7/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.9079\n",
      "Epoch 8/1000\n",
      "665/665 [==============================] - 0s 47us/step - loss: 0.9004\n",
      "Epoch 9/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.8917\n",
      "Epoch 10/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.8833\n",
      "Epoch 11/1000\n",
      "665/665 [==============================] - 0s 47us/step - loss: 0.8751\n",
      "Epoch 12/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.8661\n",
      "Epoch 13/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.8570\n",
      "Epoch 14/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.8480\n",
      "Epoch 15/1000\n",
      "665/665 [==============================] - 0s 51us/step - loss: 0.8407\n",
      "Epoch 16/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.8340\n",
      "Epoch 17/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.8278\n",
      "Epoch 18/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.8227\n",
      "Epoch 19/1000\n",
      "665/665 [==============================] - 0s 77us/step - loss: 0.8177\n",
      "Epoch 20/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.8127\n",
      "Epoch 21/1000\n",
      "665/665 [==============================] - 0s 54us/step - loss: 0.8089\n",
      "Epoch 22/1000\n",
      "665/665 [==============================] - 0s 48us/step - loss: 0.8045\n",
      "Epoch 23/1000\n",
      "665/665 [==============================] - 0s 50us/step - loss: 0.8009\n",
      "Epoch 24/1000\n",
      "665/665 [==============================] - 0s 47us/step - loss: 0.7970\n",
      "Epoch 25/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.7946\n",
      "Epoch 26/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.7912\n",
      "Epoch 27/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.7881\n",
      "Epoch 28/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.7858\n",
      "Epoch 29/1000\n",
      "665/665 [==============================] - 0s 80us/step - loss: 0.7839\n",
      "Epoch 30/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.7810\n",
      "Epoch 31/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.7788\n",
      "Epoch 32/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.7762\n",
      "Epoch 33/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.7749\n",
      "Epoch 34/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.7731\n",
      "Epoch 35/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.7712\n",
      "Epoch 36/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.7692\n",
      "Epoch 37/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.7675\n",
      "Epoch 38/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.7657\n",
      "Epoch 39/1000\n",
      "665/665 [==============================] - 0s 76us/step - loss: 0.7635\n",
      "Epoch 40/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.7604\n",
      "Epoch 41/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.7587\n",
      "Epoch 42/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.7569\n",
      "Epoch 43/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.7543\n",
      "Epoch 44/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.7527\n",
      "Epoch 45/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.7505\n",
      "Epoch 46/1000\n",
      "665/665 [==============================] - 0s 82us/step - loss: 0.7500\n",
      "Epoch 47/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.7488\n",
      "Epoch 48/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.7458\n",
      "Epoch 49/1000\n",
      "665/665 [==============================] - 0s 79us/step - loss: 0.7454\n",
      "Epoch 50/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.7429\n",
      "Epoch 51/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.7423\n",
      "Epoch 52/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.7407\n",
      "Epoch 53/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.7385\n",
      "Epoch 54/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.7371\n",
      "Epoch 55/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.7368\n",
      "Epoch 56/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.7337\n",
      "Epoch 57/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.7330\n",
      "Epoch 58/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.7322\n",
      "Epoch 59/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.7320\n",
      "Epoch 60/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.7300\n",
      "Epoch 61/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.7306\n",
      "Epoch 62/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.7289\n",
      "Epoch 63/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.7281\n",
      "Epoch 64/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.7274\n",
      "Epoch 65/1000\n",
      "665/665 [==============================] - 0s 77us/step - loss: 0.7272\n",
      "Epoch 66/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.7267\n",
      "Epoch 67/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.7255\n",
      "Epoch 68/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.7251\n",
      "Epoch 69/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.7243\n",
      "Epoch 70/1000\n",
      "665/665 [==============================] - 0s 37us/step - loss: 0.7243\n",
      "Epoch 71/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.7241\n",
      "Epoch 72/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.7230\n",
      "Epoch 73/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.7219\n",
      "Epoch 74/1000\n",
      "665/665 [==============================] - 0s 52us/step - loss: 0.7217\n",
      "Epoch 75/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.7209\n",
      "Epoch 76/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.7206\n",
      "Epoch 77/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.7205\n",
      "Epoch 78/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.7191\n",
      "Epoch 79/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.7194\n",
      "Epoch 80/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.7189\n",
      "Epoch 81/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.7182\n",
      "Epoch 82/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.7170\n",
      "Epoch 83/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.7177\n",
      "Epoch 84/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.7165\n",
      "Epoch 85/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.7164\n",
      "Epoch 86/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.7153\n",
      "Epoch 87/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.7152\n",
      "Epoch 88/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.7148\n",
      "Epoch 89/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.7136\n",
      "Epoch 90/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.7142\n",
      "Epoch 91/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.7131\n",
      "Epoch 92/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.7119\n",
      "Epoch 93/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.7123\n",
      "Epoch 94/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.7126\n",
      "Epoch 95/1000\n",
      "665/665 [==============================] - 0s 52us/step - loss: 0.7109\n",
      "Epoch 96/1000\n",
      "665/665 [==============================] - 0s 51us/step - loss: 0.7121\n",
      "Epoch 97/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 0s 54us/step - loss: 0.7096\n",
      "Epoch 98/1000\n",
      "665/665 [==============================] - 0s 52us/step - loss: 0.7086\n",
      "Epoch 99/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.7095\n",
      "Epoch 100/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.7088\n",
      "Epoch 101/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.7076\n",
      "Epoch 102/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.7071\n",
      "Epoch 103/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.7068\n",
      "Epoch 104/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.7055\n",
      "Epoch 105/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.7051\n",
      "Epoch 106/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.7048\n",
      "Epoch 107/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.7053\n",
      "Epoch 108/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.7042\n",
      "Epoch 109/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.7048\n",
      "Epoch 110/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.7026\n",
      "Epoch 111/1000\n",
      "665/665 [==============================] - 0s 47us/step - loss: 0.7033\n",
      "Epoch 112/1000\n",
      "665/665 [==============================] - 0s 49us/step - loss: 0.7040\n",
      "Epoch 113/1000\n",
      "665/665 [==============================] - 0s 49us/step - loss: 0.7010\n",
      "Epoch 114/1000\n",
      "665/665 [==============================] - 0s 55us/step - loss: 0.7022\n",
      "Epoch 115/1000\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.407 - 0s 99us/step - loss: 0.7009\n",
      "Epoch 116/1000\n",
      "665/665 [==============================] - 0s 82us/step - loss: 0.7008\n",
      "Epoch 117/1000\n",
      "665/665 [==============================] - 0s 55us/step - loss: 0.7001\n",
      "Epoch 118/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.7011\n",
      "Epoch 119/1000\n",
      "665/665 [==============================] - 0s 52us/step - loss: 0.7004\n",
      "Epoch 120/1000\n",
      "665/665 [==============================] - 0s 50us/step - loss: 0.6994\n",
      "Epoch 121/1000\n",
      "665/665 [==============================] - 0s 51us/step - loss: 0.7005\n",
      "Epoch 122/1000\n",
      "665/665 [==============================] - 0s 49us/step - loss: 0.6985\n",
      "Epoch 123/1000\n",
      "665/665 [==============================] - 0s 51us/step - loss: 0.6991\n",
      "Epoch 124/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6980\n",
      "Epoch 125/1000\n",
      "665/665 [==============================] - 0s 79us/step - loss: 0.6976\n",
      "Epoch 126/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6983\n",
      "Epoch 127/1000\n",
      "665/665 [==============================] - 0s 51us/step - loss: 0.6977\n",
      "Epoch 128/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.6978\n",
      "Epoch 129/1000\n",
      "665/665 [==============================] - 0s 52us/step - loss: 0.6972\n",
      "Epoch 130/1000\n",
      "665/665 [==============================] - 0s 52us/step - loss: 0.6969\n",
      "Epoch 131/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.6969\n",
      "Epoch 132/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.6948\n",
      "Epoch 133/1000\n",
      "665/665 [==============================] - 0s 50us/step - loss: 0.6951\n",
      "Epoch 134/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.6955\n",
      "Epoch 135/1000\n",
      "665/665 [==============================] - 0s 54us/step - loss: 0.6959\n",
      "Epoch 136/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.6953\n",
      "Epoch 137/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6946\n",
      "Epoch 138/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6947\n",
      "Epoch 139/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6939\n",
      "Epoch 140/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6946\n",
      "Epoch 141/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.6934\n",
      "Epoch 142/1000\n",
      "665/665 [==============================] - 0s 52us/step - loss: 0.6932\n",
      "Epoch 143/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.6939\n",
      "Epoch 144/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.6929\n",
      "Epoch 145/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.6927\n",
      "Epoch 146/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.6928\n",
      "Epoch 147/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.6930\n",
      "Epoch 148/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.6927\n",
      "Epoch 149/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6911\n",
      "Epoch 150/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.6913\n",
      "Epoch 151/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6933\n",
      "Epoch 152/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.6917\n",
      "Epoch 153/1000\n",
      "665/665 [==============================] - 0s 55us/step - loss: 0.6905\n",
      "Epoch 154/1000\n",
      "665/665 [==============================] - 0s 55us/step - loss: 0.6920\n",
      "Epoch 155/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6896\n",
      "Epoch 156/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6903\n",
      "Epoch 157/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.6904\n",
      "Epoch 158/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6908\n",
      "Epoch 159/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.6908\n",
      "Epoch 160/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.6899\n",
      "Epoch 161/1000\n",
      "665/665 [==============================] - 0s 51us/step - loss: 0.6881\n",
      "Epoch 162/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6901\n",
      "Epoch 163/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.6894\n",
      "Epoch 164/1000\n",
      "665/665 [==============================] - 0s 55us/step - loss: 0.6891\n",
      "Epoch 165/1000\n",
      "665/665 [==============================] - 0s 54us/step - loss: 0.6886\n",
      "Epoch 166/1000\n",
      "665/665 [==============================] - 0s 55us/step - loss: 0.6894\n",
      "Epoch 167/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.6883\n",
      "Epoch 168/1000\n",
      "665/665 [==============================] - 0s 55us/step - loss: 0.6885\n",
      "Epoch 169/1000\n",
      "665/665 [==============================] - 0s 52us/step - loss: 0.6883\n",
      "Epoch 170/1000\n",
      "665/665 [==============================] - 0s 50us/step - loss: 0.6871\n",
      "Epoch 171/1000\n",
      "665/665 [==============================] - 0s 51us/step - loss: 0.6884\n",
      "Epoch 172/1000\n",
      "665/665 [==============================] - 0s 50us/step - loss: 0.6877\n",
      "Epoch 173/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.6876\n",
      "Epoch 174/1000\n",
      "665/665 [==============================] - 0s 51us/step - loss: 0.6872\n",
      "Epoch 175/1000\n",
      "665/665 [==============================] - 0s 50us/step - loss: 0.6873\n",
      "Epoch 176/1000\n",
      "665/665 [==============================] - 0s 51us/step - loss: 0.6866\n",
      "Epoch 177/1000\n",
      "665/665 [==============================] - 0s 55us/step - loss: 0.6877\n",
      "Epoch 178/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6871\n",
      "Epoch 179/1000\n",
      "665/665 [==============================] - 0s 54us/step - loss: 0.6874\n",
      "Epoch 180/1000\n",
      "665/665 [==============================] - 0s 52us/step - loss: 0.6865\n",
      "Epoch 181/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.6856\n",
      "Epoch 182/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.6869\n",
      "Epoch 183/1000\n",
      "665/665 [==============================] - 0s 54us/step - loss: 0.6866\n",
      "Epoch 184/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6862\n",
      "Epoch 185/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.6865\n",
      "Epoch 186/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.6855\n",
      "Epoch 187/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.6865\n",
      "Epoch 188/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.6861\n",
      "Epoch 189/1000\n",
      "665/665 [==============================] - 0s 54us/step - loss: 0.6860\n",
      "Epoch 190/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.6850\n",
      "Epoch 191/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.6849\n",
      "Epoch 192/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 0s 57us/step - loss: 0.6849\n",
      "Epoch 193/1000\n",
      "665/665 [==============================] - 0s 55us/step - loss: 0.6848\n",
      "Epoch 194/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.6856\n",
      "Epoch 195/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.6848\n",
      "Epoch 196/1000\n",
      "665/665 [==============================] - 0s 55us/step - loss: 0.6836\n",
      "Epoch 197/1000\n",
      "665/665 [==============================] - 0s 54us/step - loss: 0.6852\n",
      "Epoch 198/1000\n",
      "665/665 [==============================] - 0s 51us/step - loss: 0.6840\n",
      "Epoch 199/1000\n",
      "665/665 [==============================] - 0s 54us/step - loss: 0.6849\n",
      "Epoch 200/1000\n",
      "665/665 [==============================] - 0s 55us/step - loss: 0.6855\n",
      "Epoch 201/1000\n",
      "665/665 [==============================] - 0s 55us/step - loss: 0.6833\n",
      "Epoch 202/1000\n",
      "665/665 [==============================] - 0s 83us/step - loss: 0.6834\n",
      "Epoch 203/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6847\n",
      "Epoch 204/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.6839\n",
      "Epoch 205/1000\n",
      "665/665 [==============================] - 0s 52us/step - loss: 0.6842\n",
      "Epoch 206/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.6837\n",
      "Epoch 207/1000\n",
      "665/665 [==============================] - 0s 52us/step - loss: 0.6832\n",
      "Epoch 208/1000\n",
      "665/665 [==============================] - 0s 114us/step - loss: 0.6831\n",
      "Epoch 209/1000\n",
      "665/665 [==============================] - 0s 95us/step - loss: 0.6833\n",
      "Epoch 210/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6832\n",
      "Epoch 211/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6834\n",
      "Epoch 212/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6831\n",
      "Epoch 213/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6813\n",
      "Epoch 214/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6830\n",
      "Epoch 215/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6820\n",
      "Epoch 216/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6821\n",
      "Epoch 217/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.6817\n",
      "Epoch 218/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6815\n",
      "Epoch 219/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6807\n",
      "Epoch 220/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6819\n",
      "Epoch 221/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6800\n",
      "Epoch 222/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6811\n",
      "Epoch 223/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6826\n",
      "Epoch 224/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6811\n",
      "Epoch 225/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6800\n",
      "Epoch 226/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6799\n",
      "Epoch 227/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6809\n",
      "Epoch 228/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6793\n",
      "Epoch 229/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6796\n",
      "Epoch 230/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6792\n",
      "Epoch 231/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6794\n",
      "Epoch 232/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6790\n",
      "Epoch 233/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6791\n",
      "Epoch 234/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6792\n",
      "Epoch 235/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6794\n",
      "Epoch 236/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6780\n",
      "Epoch 237/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6776\n",
      "Epoch 238/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6782\n",
      "Epoch 239/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6783\n",
      "Epoch 240/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6766\n",
      "Epoch 241/1000\n",
      "665/665 [==============================] - 0s 81us/step - loss: 0.6766\n",
      "Epoch 242/1000\n",
      "665/665 [==============================] - 0s 82us/step - loss: 0.6764\n",
      "Epoch 243/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6764\n",
      "Epoch 244/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6764\n",
      "Epoch 245/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6764\n",
      "Epoch 246/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6765\n",
      "Epoch 247/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6748\n",
      "Epoch 248/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.6760\n",
      "Epoch 249/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.6755\n",
      "Epoch 250/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.6756\n",
      "Epoch 251/1000\n",
      "665/665 [==============================] - 0s 51us/step - loss: 0.6752\n",
      "Epoch 252/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.6756\n",
      "Epoch 253/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6749\n",
      "Epoch 254/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6744\n",
      "Epoch 255/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6753\n",
      "Epoch 256/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6747\n",
      "Epoch 257/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6741\n",
      "Epoch 258/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6748\n",
      "Epoch 259/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6740\n",
      "Epoch 260/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6744\n",
      "Epoch 261/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6734\n",
      "Epoch 262/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6740\n",
      "Epoch 263/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6725\n",
      "Epoch 264/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6732\n",
      "Epoch 265/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6737\n",
      "Epoch 266/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6719\n",
      "Epoch 267/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6736\n",
      "Epoch 268/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6722\n",
      "Epoch 269/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6724\n",
      "Epoch 270/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6718\n",
      "Epoch 271/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6720\n",
      "Epoch 272/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6723\n",
      "Epoch 273/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6719\n",
      "Epoch 274/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6723\n",
      "Epoch 275/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6714\n",
      "Epoch 276/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6716\n",
      "Epoch 277/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6716\n",
      "Epoch 278/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6711\n",
      "Epoch 279/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6705\n",
      "Epoch 280/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6709\n",
      "Epoch 281/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6707\n",
      "Epoch 282/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6701\n",
      "Epoch 283/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6707\n",
      "Epoch 284/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6702\n",
      "Epoch 285/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6696\n",
      "Epoch 286/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6704\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 0s 65us/step - loss: 0.6697\n",
      "Epoch 288/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6690\n",
      "Epoch 289/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6701\n",
      "Epoch 290/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6693\n",
      "Epoch 291/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6679\n",
      "Epoch 292/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6702\n",
      "Epoch 293/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6695\n",
      "Epoch 294/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6685\n",
      "Epoch 295/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6688\n",
      "Epoch 296/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6694\n",
      "Epoch 297/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6690\n",
      "Epoch 298/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6686\n",
      "Epoch 299/1000\n",
      "665/665 [==============================] - 0s 76us/step - loss: 0.6689\n",
      "Epoch 300/1000\n",
      "665/665 [==============================] - 0s 90us/step - loss: 0.6699\n",
      "Epoch 301/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6679\n",
      "Epoch 302/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6672\n",
      "Epoch 303/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6678\n",
      "Epoch 304/1000\n",
      "665/665 [==============================] - 0s 76us/step - loss: 0.6690\n",
      "Epoch 305/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6676\n",
      "Epoch 306/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6679\n",
      "Epoch 307/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6690\n",
      "Epoch 308/1000\n",
      "665/665 [==============================] - 0s 77us/step - loss: 0.6666\n",
      "Epoch 309/1000\n",
      "665/665 [==============================] - 0s 80us/step - loss: 0.6683\n",
      "Epoch 310/1000\n",
      "665/665 [==============================] - 0s 76us/step - loss: 0.6672\n",
      "Epoch 311/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6669\n",
      "Epoch 312/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6679\n",
      "Epoch 313/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6668\n",
      "Epoch 314/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6689\n",
      "Epoch 315/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6670\n",
      "Epoch 316/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6669\n",
      "Epoch 317/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6673\n",
      "Epoch 318/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6660\n",
      "Epoch 319/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6665\n",
      "Epoch 320/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6669\n",
      "Epoch 321/1000\n",
      "665/665 [==============================] - 0s 76us/step - loss: 0.6661\n",
      "Epoch 322/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6664\n",
      "Epoch 323/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6647\n",
      "Epoch 324/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6660\n",
      "Epoch 325/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6655\n",
      "Epoch 326/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6658\n",
      "Epoch 327/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6655\n",
      "Epoch 328/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6647\n",
      "Epoch 329/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6670\n",
      "Epoch 330/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.6653\n",
      "Epoch 331/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.6646\n",
      "Epoch 332/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6653\n",
      "Epoch 333/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6646\n",
      "Epoch 334/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6643\n",
      "Epoch 335/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6645\n",
      "Epoch 336/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6641\n",
      "Epoch 337/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6646\n",
      "Epoch 338/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.6635\n",
      "Epoch 339/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.6646\n",
      "Epoch 340/1000\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.372 - 0s 61us/step - loss: 0.6640\n",
      "Epoch 341/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6637\n",
      "Epoch 342/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6623\n",
      "Epoch 343/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6632\n",
      "Epoch 344/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6621\n",
      "Epoch 345/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6626\n",
      "Epoch 346/1000\n",
      "665/665 [==============================] - 0s 95us/step - loss: 0.6630\n",
      "Epoch 347/1000\n",
      "665/665 [==============================] - 0s 98us/step - loss: 0.6631\n",
      "Epoch 348/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.6622\n",
      "Epoch 349/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6620\n",
      "Epoch 350/1000\n",
      "665/665 [==============================] - 0s 51us/step - loss: 0.6625\n",
      "Epoch 351/1000\n",
      "665/665 [==============================] - 0s 45us/step - loss: 0.6620\n",
      "Epoch 352/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6609\n",
      "Epoch 353/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6624\n",
      "Epoch 354/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6629\n",
      "Epoch 355/1000\n",
      "665/665 [==============================] - 0s 41us/step - loss: 0.6606\n",
      "Epoch 356/1000\n",
      "665/665 [==============================] - 0s 44us/step - loss: 0.6617\n",
      "Epoch 357/1000\n",
      "665/665 [==============================] - 0s 42us/step - loss: 0.6619\n",
      "Epoch 358/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6621\n",
      "Epoch 359/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.6613\n",
      "Epoch 360/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6614\n",
      "Epoch 361/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6613\n",
      "Epoch 362/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.6612\n",
      "Epoch 363/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6629\n",
      "Epoch 364/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.6602\n",
      "Epoch 365/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6610\n",
      "Epoch 366/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6606\n",
      "Epoch 367/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6611\n",
      "Epoch 368/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6604\n",
      "Epoch 369/1000\n",
      "665/665 [==============================] - 0s 54us/step - loss: 0.6612\n",
      "Epoch 370/1000\n",
      "665/665 [==============================] - 0s 43us/step - loss: 0.6608\n",
      "Epoch 371/1000\n",
      "665/665 [==============================] - 0s 52us/step - loss: 0.6600\n",
      "Epoch 372/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.6613\n",
      "Epoch 373/1000\n",
      "665/665 [==============================] - 0s 44us/step - loss: 0.6591\n",
      "Epoch 374/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.6603\n",
      "Epoch 375/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6601\n",
      "Epoch 376/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6612\n",
      "Epoch 377/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6588\n",
      "Epoch 378/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6592\n",
      "Epoch 379/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6605\n",
      "Epoch 380/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6593\n",
      "Epoch 381/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6587\n",
      "Epoch 382/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 0s 61us/step - loss: 0.6589\n",
      "Epoch 383/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6597\n",
      "Epoch 384/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6600\n",
      "Epoch 385/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6576\n",
      "Epoch 386/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6584\n",
      "Epoch 387/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6585\n",
      "Epoch 388/1000\n",
      "665/665 [==============================] - 0s 78us/step - loss: 0.6599\n",
      "Epoch 389/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6587\n",
      "Epoch 390/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6582\n",
      "Epoch 391/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6587\n",
      "Epoch 392/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6587\n",
      "Epoch 393/1000\n",
      "665/665 [==============================] - 0s 44us/step - loss: 0.6576\n",
      "Epoch 394/1000\n",
      "665/665 [==============================] - 0s 54us/step - loss: 0.6581\n",
      "Epoch 395/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.6573\n",
      "Epoch 396/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.6579\n",
      "Epoch 397/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6578\n",
      "Epoch 398/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6587\n",
      "Epoch 399/1000\n",
      "665/665 [==============================] - 0s 84us/step - loss: 0.6581\n",
      "Epoch 400/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6578\n",
      "Epoch 401/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6574\n",
      "Epoch 402/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6566\n",
      "Epoch 403/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6564\n",
      "Epoch 404/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.6569\n",
      "Epoch 405/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6570\n",
      "Epoch 406/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6562\n",
      "Epoch 407/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6569\n",
      "Epoch 408/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6556\n",
      "Epoch 409/1000\n",
      "665/665 [==============================] - 0s 86us/step - loss: 0.6563\n",
      "Epoch 410/1000\n",
      "665/665 [==============================] - 0s 78us/step - loss: 0.6563\n",
      "Epoch 411/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6561\n",
      "Epoch 412/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6563\n",
      "Epoch 413/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6563\n",
      "Epoch 414/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6559\n",
      "Epoch 415/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6556\n",
      "Epoch 416/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6552\n",
      "Epoch 417/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6541\n",
      "Epoch 418/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6560\n",
      "Epoch 419/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6555\n",
      "Epoch 420/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6549\n",
      "Epoch 421/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6562\n",
      "Epoch 422/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6560\n",
      "Epoch 423/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6545\n",
      "Epoch 424/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6543\n",
      "Epoch 425/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6541\n",
      "Epoch 426/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6535\n",
      "Epoch 427/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6541\n",
      "Epoch 428/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6541\n",
      "Epoch 429/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6541\n",
      "Epoch 430/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6543\n",
      "Epoch 431/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6546\n",
      "Epoch 432/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6527\n",
      "Epoch 433/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6549\n",
      "Epoch 434/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6556\n",
      "Epoch 435/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6520\n",
      "Epoch 436/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6542\n",
      "Epoch 437/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6536\n",
      "Epoch 438/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6533\n",
      "Epoch 439/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6538\n",
      "Epoch 440/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6525\n",
      "Epoch 441/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6529\n",
      "Epoch 442/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6535\n",
      "Epoch 443/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6536\n",
      "Epoch 444/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6537\n",
      "Epoch 445/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6529\n",
      "Epoch 446/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6531\n",
      "Epoch 447/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6525\n",
      "Epoch 448/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6534\n",
      "Epoch 449/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6526\n",
      "Epoch 450/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6529\n",
      "Epoch 451/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6533\n",
      "Epoch 452/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6528\n",
      "Epoch 453/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6521\n",
      "Epoch 454/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6539\n",
      "Epoch 455/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6516\n",
      "Epoch 456/1000\n",
      "665/665 [==============================] - 0s 76us/step - loss: 0.6532\n",
      "Epoch 457/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6515\n",
      "Epoch 458/1000\n",
      "665/665 [==============================] - 0s 42us/step - loss: 0.6518\n",
      "Epoch 459/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6526\n",
      "Epoch 460/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6518\n",
      "Epoch 461/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6514\n",
      "Epoch 462/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6516\n",
      "Epoch 463/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6517\n",
      "Epoch 464/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6525\n",
      "Epoch 465/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6513\n",
      "Epoch 466/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6513\n",
      "Epoch 467/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6511\n",
      "Epoch 468/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.6516\n",
      "Epoch 469/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6506\n",
      "Epoch 470/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6506\n",
      "Epoch 471/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.6515\n",
      "Epoch 472/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6505\n",
      "Epoch 473/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6508\n",
      "Epoch 474/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6511\n",
      "Epoch 475/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6505\n",
      "Epoch 476/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6509\n",
      "Epoch 477/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 0s 80us/step - loss: 0.6503\n",
      "Epoch 478/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6512\n",
      "Epoch 479/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6507\n",
      "Epoch 480/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6489\n",
      "Epoch 481/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6506\n",
      "Epoch 482/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6502\n",
      "Epoch 483/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6505\n",
      "Epoch 484/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6500\n",
      "Epoch 485/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6504\n",
      "Epoch 486/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6499\n",
      "Epoch 487/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6494\n",
      "Epoch 488/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6502\n",
      "Epoch 489/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6494\n",
      "Epoch 490/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6505\n",
      "Epoch 491/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6493\n",
      "Epoch 492/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6493\n",
      "Epoch 493/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6498\n",
      "Epoch 494/1000\n",
      "665/665 [==============================] - 0s 77us/step - loss: 0.6492\n",
      "Epoch 495/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6517\n",
      "Epoch 496/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6488\n",
      "Epoch 497/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6498\n",
      "Epoch 498/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6499\n",
      "Epoch 499/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6490\n",
      "Epoch 500/1000\n",
      "665/665 [==============================] - 0s 80us/step - loss: 0.6491\n",
      "Epoch 501/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6490\n",
      "Epoch 502/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6486\n",
      "Epoch 503/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6489\n",
      "Epoch 504/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6483\n",
      "Epoch 505/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6485\n",
      "Epoch 506/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6489\n",
      "Epoch 507/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6476\n",
      "Epoch 508/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6491\n",
      "Epoch 509/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6484\n",
      "Epoch 510/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.6475\n",
      "Epoch 511/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6496\n",
      "Epoch 512/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6488\n",
      "Epoch 513/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6492\n",
      "Epoch 514/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6473\n",
      "Epoch 515/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6490\n",
      "Epoch 516/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6485\n",
      "Epoch 517/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6474\n",
      "Epoch 518/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.6476\n",
      "Epoch 519/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6486\n",
      "Epoch 520/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6477\n",
      "Epoch 521/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6473\n",
      "Epoch 522/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6486\n",
      "Epoch 523/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6472\n",
      "Epoch 524/1000\n",
      "665/665 [==============================] - 0s 43us/step - loss: 0.6465\n",
      "Epoch 525/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.6481\n",
      "Epoch 526/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6467\n",
      "Epoch 527/1000\n",
      "665/665 [==============================] - 0s 52us/step - loss: 0.6489\n",
      "Epoch 528/1000\n",
      "665/665 [==============================] - 0s 45us/step - loss: 0.6479\n",
      "Epoch 529/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6471\n",
      "Epoch 530/1000\n",
      "665/665 [==============================] - 0s 47us/step - loss: 0.6473\n",
      "Epoch 531/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6475\n",
      "Epoch 532/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6471\n",
      "Epoch 533/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6464\n",
      "Epoch 534/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6474\n",
      "Epoch 535/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6475\n",
      "Epoch 536/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6454\n",
      "Epoch 537/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6479\n",
      "Epoch 538/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6473\n",
      "Epoch 539/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6470\n",
      "Epoch 540/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6470\n",
      "Epoch 541/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6465\n",
      "Epoch 542/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.6469\n",
      "Epoch 543/1000\n",
      "665/665 [==============================] - 0s 48us/step - loss: 0.6462\n",
      "Epoch 544/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.6466\n",
      "Epoch 545/1000\n",
      "665/665 [==============================] - 0s 55us/step - loss: 0.6467\n",
      "Epoch 546/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6465\n",
      "Epoch 547/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6463\n",
      "Epoch 548/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6467\n",
      "Epoch 549/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6457\n",
      "Epoch 550/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6449\n",
      "Epoch 551/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6463\n",
      "Epoch 552/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6464\n",
      "Epoch 553/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6462\n",
      "Epoch 554/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6460\n",
      "Epoch 555/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6452\n",
      "Epoch 556/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6456\n",
      "Epoch 557/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6463\n",
      "Epoch 558/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6449\n",
      "Epoch 559/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6462\n",
      "Epoch 560/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6446\n",
      "Epoch 561/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6465\n",
      "Epoch 562/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6460\n",
      "Epoch 563/1000\n",
      "665/665 [==============================] - 0s 41us/step - loss: 0.6451\n",
      "Epoch 564/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.6445\n",
      "Epoch 565/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6458\n",
      "Epoch 566/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6449\n",
      "Epoch 567/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6441\n",
      "Epoch 568/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6463\n",
      "Epoch 569/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6454\n",
      "Epoch 570/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6449\n",
      "Epoch 571/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6454\n",
      "Epoch 572/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 0s 59us/step - loss: 0.6449\n",
      "Epoch 573/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6452\n",
      "Epoch 574/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6454\n",
      "Epoch 575/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6434\n",
      "Epoch 576/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6467\n",
      "Epoch 577/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6460\n",
      "Epoch 578/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6440\n",
      "Epoch 579/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6449\n",
      "Epoch 580/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6434\n",
      "Epoch 581/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6436\n",
      "Epoch 582/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6465\n",
      "Epoch 583/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6439\n",
      "Epoch 584/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6438\n",
      "Epoch 585/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6450\n",
      "Epoch 586/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6449\n",
      "Epoch 587/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6435\n",
      "Epoch 588/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6441\n",
      "Epoch 589/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6441\n",
      "Epoch 590/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6446\n",
      "Epoch 591/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6426\n",
      "Epoch 592/1000\n",
      "665/665 [==============================] - 0s 76us/step - loss: 0.6442\n",
      "Epoch 593/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6426\n",
      "Epoch 594/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6430\n",
      "Epoch 595/1000\n",
      "665/665 [==============================] - 0s 78us/step - loss: 0.6451\n",
      "Epoch 596/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6435\n",
      "Epoch 597/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6438\n",
      "Epoch 598/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6437\n",
      "Epoch 599/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6439\n",
      "Epoch 600/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6439\n",
      "Epoch 601/1000\n",
      "665/665 [==============================] - 0s 79us/step - loss: 0.6430\n",
      "Epoch 602/1000\n",
      "665/665 [==============================] - 0s 79us/step - loss: 0.6437\n",
      "Epoch 603/1000\n",
      "665/665 [==============================] - 0s 77us/step - loss: 0.6420\n",
      "Epoch 604/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6430\n",
      "Epoch 605/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6444\n",
      "Epoch 606/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6418\n",
      "Epoch 607/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6430\n",
      "Epoch 608/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6435\n",
      "Epoch 609/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6413\n",
      "Epoch 610/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6434\n",
      "Epoch 611/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6421\n",
      "Epoch 612/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6423\n",
      "Epoch 613/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6428\n",
      "Epoch 614/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6430\n",
      "Epoch 615/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6421\n",
      "Epoch 616/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6428\n",
      "Epoch 617/1000\n",
      "665/665 [==============================] - 0s 77us/step - loss: 0.6417\n",
      "Epoch 618/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6425\n",
      "Epoch 619/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6425\n",
      "Epoch 620/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6418\n",
      "Epoch 621/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6424\n",
      "Epoch 622/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6419\n",
      "Epoch 623/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6418\n",
      "Epoch 624/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6429\n",
      "Epoch 625/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6427\n",
      "Epoch 626/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6417\n",
      "Epoch 627/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6430\n",
      "Epoch 628/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6417\n",
      "Epoch 629/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6416\n",
      "Epoch 630/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6419\n",
      "Epoch 631/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6413\n",
      "Epoch 632/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6406\n",
      "Epoch 633/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6424\n",
      "Epoch 634/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6408\n",
      "Epoch 635/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6417\n",
      "Epoch 636/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6403\n",
      "Epoch 637/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6402\n",
      "Epoch 638/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6406\n",
      "Epoch 639/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6407\n",
      "Epoch 640/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6409\n",
      "Epoch 641/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6405\n",
      "Epoch 642/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6388\n",
      "Epoch 643/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6402\n",
      "Epoch 644/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6400\n",
      "Epoch 645/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6400\n",
      "Epoch 646/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6411\n",
      "Epoch 647/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6408\n",
      "Epoch 648/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6403\n",
      "Epoch 649/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6394\n",
      "Epoch 650/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6403\n",
      "Epoch 651/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6390\n",
      "Epoch 652/1000\n",
      "665/665 [==============================] - 0s 45us/step - loss: 0.6393\n",
      "Epoch 653/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6387\n",
      "Epoch 654/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6397\n",
      "Epoch 655/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6385\n",
      "Epoch 656/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6399\n",
      "Epoch 657/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6393\n",
      "Epoch 658/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6397\n",
      "Epoch 659/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6381\n",
      "Epoch 660/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6386\n",
      "Epoch 661/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.6384\n",
      "Epoch 662/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6388\n",
      "Epoch 663/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6379\n",
      "Epoch 664/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6386\n",
      "Epoch 665/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6375\n",
      "Epoch 666/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6370\n",
      "Epoch 667/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 0s 71us/step - loss: 0.6379\n",
      "Epoch 668/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6363\n",
      "Epoch 669/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6373\n",
      "Epoch 670/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6374\n",
      "Epoch 671/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6365\n",
      "Epoch 672/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6377\n",
      "Epoch 673/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6372\n",
      "Epoch 674/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6357\n",
      "Epoch 675/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6366\n",
      "Epoch 676/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6368\n",
      "Epoch 677/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6359\n",
      "Epoch 678/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6371\n",
      "Epoch 679/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6362\n",
      "Epoch 680/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6361\n",
      "Epoch 681/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6362\n",
      "Epoch 682/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6353\n",
      "Epoch 683/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6361\n",
      "Epoch 684/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6351\n",
      "Epoch 685/1000\n",
      "665/665 [==============================] - 0s 55us/step - loss: 0.6353\n",
      "Epoch 686/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6357\n",
      "Epoch 687/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6367\n",
      "Epoch 688/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6343\n",
      "Epoch 689/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6356\n",
      "Epoch 690/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6359\n",
      "Epoch 691/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6346\n",
      "Epoch 692/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6351\n",
      "Epoch 693/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6346\n",
      "Epoch 694/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6365\n",
      "Epoch 695/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6351\n",
      "Epoch 696/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6345\n",
      "Epoch 697/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6340\n",
      "Epoch 698/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6343\n",
      "Epoch 699/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6343\n",
      "Epoch 700/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.6334\n",
      "Epoch 701/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6341\n",
      "Epoch 702/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6321\n",
      "Epoch 703/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6340\n",
      "Epoch 704/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6342\n",
      "Epoch 705/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6336\n",
      "Epoch 706/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6337\n",
      "Epoch 707/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6333\n",
      "Epoch 708/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6322\n",
      "Epoch 709/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6345\n",
      "Epoch 710/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6338\n",
      "Epoch 711/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6332\n",
      "Epoch 712/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6332\n",
      "Epoch 713/1000\n",
      "665/665 [==============================] - 0s 54us/step - loss: 0.6323\n",
      "Epoch 714/1000\n",
      "665/665 [==============================] - 0s 48us/step - loss: 0.6336\n",
      "Epoch 715/1000\n",
      "665/665 [==============================] - 0s 55us/step - loss: 0.6328\n",
      "Epoch 716/1000\n",
      "665/665 [==============================] - 0s 54us/step - loss: 0.6323\n",
      "Epoch 717/1000\n",
      "665/665 [==============================] - 0s 54us/step - loss: 0.6330\n",
      "Epoch 718/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6331\n",
      "Epoch 719/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6335\n",
      "Epoch 720/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6323\n",
      "Epoch 721/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6323\n",
      "Epoch 722/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6329\n",
      "Epoch 723/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6326\n",
      "Epoch 724/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6308\n",
      "Epoch 725/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6342\n",
      "Epoch 726/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6314\n",
      "Epoch 727/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6320\n",
      "Epoch 728/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6320\n",
      "Epoch 729/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6329\n",
      "Epoch 730/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6319\n",
      "Epoch 731/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6310\n",
      "Epoch 732/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6308\n",
      "Epoch 733/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6314\n",
      "Epoch 734/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6300\n",
      "Epoch 735/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6305\n",
      "Epoch 736/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6307\n",
      "Epoch 737/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6298\n",
      "Epoch 738/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6293\n",
      "Epoch 739/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6298\n",
      "Epoch 740/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6302\n",
      "Epoch 741/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6284\n",
      "Epoch 742/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6299\n",
      "Epoch 743/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6289\n",
      "Epoch 744/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6292\n",
      "Epoch 745/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6293\n",
      "Epoch 746/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6299\n",
      "Epoch 747/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6287\n",
      "Epoch 748/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6291\n",
      "Epoch 749/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6282\n",
      "Epoch 750/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6284\n",
      "Epoch 751/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6293\n",
      "Epoch 752/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6276\n",
      "Epoch 753/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6277\n",
      "Epoch 754/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6283\n",
      "Epoch 755/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6285\n",
      "Epoch 756/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6271\n",
      "Epoch 757/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6282\n",
      "Epoch 758/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6275\n",
      "Epoch 759/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.6283\n",
      "Epoch 760/1000\n",
      "665/665 [==============================] - 0s 45us/step - loss: 0.6278\n",
      "Epoch 761/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.6277\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 0s 48us/step - loss: 0.6259\n",
      "Epoch 763/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.6276\n",
      "Epoch 764/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.6262\n",
      "Epoch 765/1000\n",
      "665/665 [==============================] - 0s 55us/step - loss: 0.6276\n",
      "Epoch 766/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6277\n",
      "Epoch 767/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6264\n",
      "Epoch 768/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6264\n",
      "Epoch 769/1000\n",
      "665/665 [==============================] - 0s 85us/step - loss: 0.6267\n",
      "Epoch 770/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6265\n",
      "Epoch 771/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6265\n",
      "Epoch 772/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6260\n",
      "Epoch 773/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6255\n",
      "Epoch 774/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6267\n",
      "Epoch 775/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6276\n",
      "Epoch 776/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6257\n",
      "Epoch 777/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6272\n",
      "Epoch 778/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6247\n",
      "Epoch 779/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6244\n",
      "Epoch 780/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6249\n",
      "Epoch 781/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6245\n",
      "Epoch 782/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6260\n",
      "Epoch 783/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6265\n",
      "Epoch 784/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6249\n",
      "Epoch 785/1000\n",
      "665/665 [==============================] - 0s 76us/step - loss: 0.6254\n",
      "Epoch 786/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6260\n",
      "Epoch 787/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6257\n",
      "Epoch 788/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6249\n",
      "Epoch 789/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6237\n",
      "Epoch 790/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6254\n",
      "Epoch 791/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6253\n",
      "Epoch 792/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6256\n",
      "Epoch 793/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.6242\n",
      "Epoch 794/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6241\n",
      "Epoch 795/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6234\n",
      "Epoch 796/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6254\n",
      "Epoch 797/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6238\n",
      "Epoch 798/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6226\n",
      "Epoch 799/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6241\n",
      "Epoch 800/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6249\n",
      "Epoch 801/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6219\n",
      "Epoch 802/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6248\n",
      "Epoch 803/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6233\n",
      "Epoch 804/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6234\n",
      "Epoch 805/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6243\n",
      "Epoch 806/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6236\n",
      "Epoch 807/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6240\n",
      "Epoch 808/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6229\n",
      "Epoch 809/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6230\n",
      "Epoch 810/1000\n",
      "665/665 [==============================] - 0s 56us/step - loss: 0.6231\n",
      "Epoch 811/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.6231\n",
      "Epoch 812/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6229\n",
      "Epoch 813/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6233\n",
      "Epoch 814/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6234\n",
      "Epoch 815/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6221\n",
      "Epoch 816/1000\n",
      "665/665 [==============================] - 0s 49us/step - loss: 0.6232\n",
      "Epoch 817/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6225\n",
      "Epoch 818/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6224\n",
      "Epoch 819/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6221\n",
      "Epoch 820/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6226\n",
      "Epoch 821/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6220\n",
      "Epoch 822/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6209\n",
      "Epoch 823/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6230\n",
      "Epoch 824/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6230\n",
      "Epoch 825/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6223\n",
      "Epoch 826/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6217\n",
      "Epoch 827/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6218\n",
      "Epoch 828/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6225\n",
      "Epoch 829/1000\n",
      "665/665 [==============================] - 0s 82us/step - loss: 0.6213\n",
      "Epoch 830/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6207\n",
      "Epoch 831/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6219\n",
      "Epoch 832/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6212\n",
      "Epoch 833/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6226\n",
      "Epoch 834/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6209\n",
      "Epoch 835/1000\n",
      "665/665 [==============================] - 0s 76us/step - loss: 0.6214\n",
      "Epoch 836/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6221\n",
      "Epoch 837/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6202\n",
      "Epoch 838/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6221\n",
      "Epoch 839/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6227\n",
      "Epoch 840/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6211\n",
      "Epoch 841/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6220\n",
      "Epoch 842/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6214\n",
      "Epoch 843/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6210\n",
      "Epoch 844/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6217\n",
      "Epoch 845/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6203\n",
      "Epoch 846/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6203\n",
      "Epoch 847/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6220\n",
      "Epoch 848/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6208\n",
      "Epoch 849/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6203\n",
      "Epoch 850/1000\n",
      "665/665 [==============================] - 0s 77us/step - loss: 0.6205\n",
      "Epoch 851/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6212\n",
      "Epoch 852/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6208\n",
      "Epoch 853/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6213\n",
      "Epoch 854/1000\n",
      "665/665 [==============================] - 0s 76us/step - loss: 0.6215\n",
      "Epoch 855/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6199\n",
      "Epoch 856/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6213\n",
      "Epoch 857/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 0s 74us/step - loss: 0.6199\n",
      "Epoch 858/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6212\n",
      "Epoch 859/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6216\n",
      "Epoch 860/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6200\n",
      "Epoch 861/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6206\n",
      "Epoch 862/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6213\n",
      "Epoch 863/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6195\n",
      "Epoch 864/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6208\n",
      "Epoch 865/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6207\n",
      "Epoch 866/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6198\n",
      "Epoch 867/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6210\n",
      "Epoch 868/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6205\n",
      "Epoch 869/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6201\n",
      "Epoch 870/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6194\n",
      "Epoch 871/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6193\n",
      "Epoch 872/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6201\n",
      "Epoch 873/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6203\n",
      "Epoch 874/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6206\n",
      "Epoch 875/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6197\n",
      "Epoch 876/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6193\n",
      "Epoch 877/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6197\n",
      "Epoch 878/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6199\n",
      "Epoch 879/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6196\n",
      "Epoch 880/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6193\n",
      "Epoch 881/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6205\n",
      "Epoch 882/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6187\n",
      "Epoch 883/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6193\n",
      "Epoch 884/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6201\n",
      "Epoch 885/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6183\n",
      "Epoch 886/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6195\n",
      "Epoch 887/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6183\n",
      "Epoch 888/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.6176\n",
      "Epoch 889/1000\n",
      "665/665 [==============================] - 0s 58us/step - loss: 0.6201\n",
      "Epoch 890/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6193\n",
      "Epoch 891/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6178\n",
      "Epoch 892/1000\n",
      "665/665 [==============================] - 0s 57us/step - loss: 0.6186\n",
      "Epoch 893/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6200\n",
      "Epoch 894/1000\n",
      "665/665 [==============================] - 0s 53us/step - loss: 0.6191\n",
      "Epoch 895/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6200\n",
      "Epoch 896/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6173\n",
      "Epoch 897/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6188\n",
      "Epoch 898/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6188\n",
      "Epoch 899/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6205\n",
      "Epoch 900/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6184\n",
      "Epoch 901/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6185\n",
      "Epoch 902/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6197\n",
      "Epoch 903/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6191\n",
      "Epoch 904/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6182\n",
      "Epoch 905/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6166\n",
      "Epoch 906/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6194\n",
      "Epoch 907/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6190\n",
      "Epoch 908/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6181\n",
      "Epoch 909/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6188\n",
      "Epoch 910/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6180\n",
      "Epoch 911/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6183\n",
      "Epoch 912/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6190\n",
      "Epoch 913/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6193\n",
      "Epoch 914/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6187\n",
      "Epoch 915/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6183\n",
      "Epoch 916/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6179\n",
      "Epoch 917/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6197\n",
      "Epoch 918/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6162\n",
      "Epoch 919/1000\n",
      "665/665 [==============================] - 0s 49us/step - loss: 0.6194\n",
      "Epoch 920/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6185\n",
      "Epoch 921/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6189\n",
      "Epoch 922/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6172\n",
      "Epoch 923/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6184\n",
      "Epoch 924/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6180\n",
      "Epoch 925/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6190\n",
      "Epoch 926/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6172\n",
      "Epoch 927/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6170\n",
      "Epoch 928/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6178\n",
      "Epoch 929/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6184\n",
      "Epoch 930/1000\n",
      "665/665 [==============================] - 0s 52us/step - loss: 0.6181\n",
      "Epoch 931/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6180\n",
      "Epoch 932/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6164\n",
      "Epoch 933/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6185\n",
      "Epoch 934/1000\n",
      "665/665 [==============================] - 0s 59us/step - loss: 0.6178\n",
      "Epoch 935/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6177\n",
      "Epoch 936/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6168\n",
      "Epoch 937/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6182\n",
      "Epoch 938/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6177\n",
      "Epoch 939/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6191\n",
      "Epoch 940/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6183\n",
      "Epoch 941/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6169\n",
      "Epoch 942/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6188\n",
      "Epoch 943/1000\n",
      "665/665 [==============================] - 0s 66us/step - loss: 0.6183\n",
      "Epoch 944/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6169\n",
      "Epoch 945/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6187\n",
      "Epoch 946/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6177\n",
      "Epoch 947/1000\n",
      "665/665 [==============================] - 0s 77us/step - loss: 0.6168\n",
      "Epoch 948/1000\n",
      "665/665 [==============================] - 0s 76us/step - loss: 0.6165\n",
      "Epoch 949/1000\n",
      "665/665 [==============================] - 0s 69us/step - loss: 0.6174\n",
      "Epoch 950/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6173\n",
      "Epoch 951/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6159\n",
      "Epoch 952/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 0s 76us/step - loss: 0.6181\n",
      "Epoch 953/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6179\n",
      "Epoch 954/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6164\n",
      "Epoch 955/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6184\n",
      "Epoch 956/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6183\n",
      "Epoch 957/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6160\n",
      "Epoch 958/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6183\n",
      "Epoch 959/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6176\n",
      "Epoch 960/1000\n",
      "665/665 [==============================] - 0s 62us/step - loss: 0.6157\n",
      "Epoch 961/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6172\n",
      "Epoch 962/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6172\n",
      "Epoch 963/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6158\n",
      "Epoch 964/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6170\n",
      "Epoch 965/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6169\n",
      "Epoch 966/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6179\n",
      "Epoch 967/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6171\n",
      "Epoch 968/1000\n",
      "665/665 [==============================] - 0s 80us/step - loss: 0.6168\n",
      "Epoch 969/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6172\n",
      "Epoch 970/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6167\n",
      "Epoch 971/1000\n",
      "665/665 [==============================] - 0s 76us/step - loss: 0.6178\n",
      "Epoch 972/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6155\n",
      "Epoch 973/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6170\n",
      "Epoch 974/1000\n",
      "665/665 [==============================] - 0s 72us/step - loss: 0.6171\n",
      "Epoch 975/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6165\n",
      "Epoch 976/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6177\n",
      "Epoch 977/1000\n",
      "665/665 [==============================] - 0s 60us/step - loss: 0.6174\n",
      "Epoch 978/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6167\n",
      "Epoch 979/1000\n",
      "665/665 [==============================] - 0s 61us/step - loss: 0.6170\n",
      "Epoch 980/1000\n",
      "665/665 [==============================] - 0s 64us/step - loss: 0.6164\n",
      "Epoch 981/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6171\n",
      "Epoch 982/1000\n",
      "665/665 [==============================] - 0s 65us/step - loss: 0.6165\n",
      "Epoch 983/1000\n",
      "665/665 [==============================] - 0s 76us/step - loss: 0.6166\n",
      "Epoch 984/1000\n",
      "665/665 [==============================] - 0s 63us/step - loss: 0.6183\n",
      "Epoch 985/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6180\n",
      "Epoch 986/1000\n",
      "665/665 [==============================] - 0s 74us/step - loss: 0.6143\n",
      "Epoch 987/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6170\n",
      "Epoch 988/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6164\n",
      "Epoch 989/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6164\n",
      "Epoch 990/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6153\n",
      "Epoch 991/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6175\n",
      "Epoch 992/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6167\n",
      "Epoch 993/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6160\n",
      "Epoch 994/1000\n",
      "665/665 [==============================] - 0s 70us/step - loss: 0.6161\n",
      "Epoch 995/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6165\n",
      "Epoch 996/1000\n",
      "665/665 [==============================] - 0s 67us/step - loss: 0.6167\n",
      "Epoch 997/1000\n",
      "665/665 [==============================] - 0s 73us/step - loss: 0.6163\n",
      "Epoch 998/1000\n",
      "665/665 [==============================] - 0s 75us/step - loss: 0.6167\n",
      "Epoch 999/1000\n",
      "665/665 [==============================] - 0s 71us/step - loss: 0.6149\n",
      "Epoch 1000/1000\n",
      "665/665 [==============================] - 0s 68us/step - loss: 0.6161\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=5, activation='relu', input_dim=11))\n",
    "model.add(Dense(units=5, activation='relu'))\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "history = model.fit(normal_X_ltrain, normal_y_ltrain, epochs=1000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a3192b358>]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.293711293893226e-07"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_y_ltest_pred = model.predict(normal_X_ltest)\n",
    "y_ltest_pred = unnormalize_columns(normal_y_ltest_pred, y_ltest, y_ltest)\n",
    "mean_squared_error(y_ltest_pred, y_ltest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Housing Units</th>\n",
       "      <th>Year</th>\n",
       "      <th>Median Year Structure Built</th>\n",
       "      <th>Median Year Moved In</th>\n",
       "      <th>Percent with Bachelor's degree</th>\n",
       "      <th>Median rent burden</th>\n",
       "      <th>Percent Black</th>\n",
       "      <th>Percent White</th>\n",
       "      <th>Percent Asian</th>\n",
       "      <th>Percent Native</th>\n",
       "      <th>Neighbors Mean</th>\n",
       "      <th>Number Stops</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3056.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>44.300000</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>0.007793</td>\n",
       "      <td>0.842769</td>\n",
       "      <td>0.111850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2379.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>38.100000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.618689</td>\n",
       "      <td>0.330135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005.522124</td>\n",
       "      <td>2018</td>\n",
       "      <td>1943.230088</td>\n",
       "      <td>2009.823009</td>\n",
       "      <td>32.619469</td>\n",
       "      <td>27.650442</td>\n",
       "      <td>0.039850</td>\n",
       "      <td>0.461255</td>\n",
       "      <td>0.359640</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2883.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>37.400000</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.596771</td>\n",
       "      <td>0.284177</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005.522124</td>\n",
       "      <td>2018</td>\n",
       "      <td>1943.230088</td>\n",
       "      <td>2009.823009</td>\n",
       "      <td>32.619469</td>\n",
       "      <td>27.650442</td>\n",
       "      <td>0.039850</td>\n",
       "      <td>0.461255</td>\n",
       "      <td>0.359640</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total Housing Units  Year  Median Year Structure Built  \\\n",
       "0          3056.000000  2017                  1939.000000   \n",
       "1          2379.000000  2017                  1939.000000   \n",
       "2          2005.522124  2018                  1943.230088   \n",
       "3          2883.000000  2017                  1939.000000   \n",
       "4          2005.522124  2018                  1943.230088   \n",
       "\n",
       "   Median Year Moved In  Percent with Bachelor's degree  Median rent burden  \\\n",
       "0           2011.000000                       44.300000           23.300000   \n",
       "1           2010.000000                       38.100000           21.000000   \n",
       "2           2009.823009                       32.619469           27.650442   \n",
       "3           2008.000000                       37.400000           23.300000   \n",
       "4           2009.823009                       32.619469           27.650442   \n",
       "\n",
       "   Percent Black  Percent White  Percent Asian  Percent Native  \\\n",
       "0       0.007793       0.842769       0.111850        0.000000   \n",
       "1       0.000000       0.618689       0.330135        0.000000   \n",
       "2       0.039850       0.461255       0.359640        0.003297   \n",
       "3       0.000215       0.596771       0.284177        0.000861   \n",
       "4       0.039850       0.461255       0.359640        0.003297   \n",
       "\n",
       "   Neighbors Mean  Number Stops  geometry  \n",
       "0             1.0            32       0.0  \n",
       "1             3.0            13       0.0  \n",
       "2             3.0            13       0.0  \n",
       "3             6.0            24       0.0  \n",
       "4             6.0            24       0.0  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features_df = pd.read_csv('data/test_features_17_with_shuttles.csv')\n",
    "test_features = ['Total Housing Units','Percent Asian', 'Percent White', 'Percent Black','Median Year Structure Built',\n",
    "           'Number Stops','Year', 'Percent Native', 'Median Year Moved In', 'Median rent burden', \"Percent with Bachelor's degree\",\n",
    "           'Neighbors Mean', \"geometry\"]\n",
    "\n",
    "X_future = test_features_df.loc[:, test_features_df.columns.isin(test_features)]\n",
    "#features_df_keep.to_csv('data/exploratory_data.csv', index=False)\n",
    "\n",
    "X_future.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection with LASSO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Housing Units</th>\n",
       "      <th>Median Year Structure Built</th>\n",
       "      <th>Median Year Moved In</th>\n",
       "      <th>Percent with Bachelor's degree</th>\n",
       "      <th>Median rent burden</th>\n",
       "      <th>Percent Black</th>\n",
       "      <th>Percent White</th>\n",
       "      <th>Percent Asian</th>\n",
       "      <th>Neighbors Mean</th>\n",
       "      <th>Number Stops</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3056.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>44.300000</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>0.007793</td>\n",
       "      <td>0.842769</td>\n",
       "      <td>0.111850</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2379.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>38.100000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.618689</td>\n",
       "      <td>0.330135</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005.522124</td>\n",
       "      <td>1943.230088</td>\n",
       "      <td>2009.823009</td>\n",
       "      <td>32.619469</td>\n",
       "      <td>27.650442</td>\n",
       "      <td>0.039850</td>\n",
       "      <td>0.461255</td>\n",
       "      <td>0.359640</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2883.000000</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>37.400000</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.596771</td>\n",
       "      <td>0.284177</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005.522124</td>\n",
       "      <td>1943.230088</td>\n",
       "      <td>2009.823009</td>\n",
       "      <td>32.619469</td>\n",
       "      <td>27.650442</td>\n",
       "      <td>0.039850</td>\n",
       "      <td>0.461255</td>\n",
       "      <td>0.359640</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total Housing Units  Median Year Structure Built  Median Year Moved In  \\\n",
       "0          3056.000000                  1939.000000           2011.000000   \n",
       "1          2379.000000                  1939.000000           2010.000000   \n",
       "2          2005.522124                  1943.230088           2009.823009   \n",
       "3          2883.000000                  1939.000000           2008.000000   \n",
       "4          2005.522124                  1943.230088           2009.823009   \n",
       "\n",
       "   Percent with Bachelor's degree  Median rent burden  Percent Black  \\\n",
       "0                       44.300000           23.300000       0.007793   \n",
       "1                       38.100000           21.000000       0.000000   \n",
       "2                       32.619469           27.650442       0.039850   \n",
       "3                       37.400000           23.300000       0.000215   \n",
       "4                       32.619469           27.650442       0.039850   \n",
       "\n",
       "   Percent White  Percent Asian  Neighbors Mean  Number Stops  geometry  \n",
       "0       0.842769       0.111850             1.0            32       0.0  \n",
       "1       0.618689       0.330135             3.0            13       0.0  \n",
       "2       0.461255       0.359640             3.0            13       0.0  \n",
       "3       0.596771       0.284177             6.0            24       0.0  \n",
       "4       0.461255       0.359640             6.0            24       0.0  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_future = X_future.loc[:, ~(X_future.columns.isin(['Percent Native', 'Year']))]\n",
    "# selected_features_future[selected_features_future.isna().sum(axis=1) > 0]\n",
    "selected_features_future.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geoid</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6075010200</td>\n",
       "      <td>0.001116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6075010300</td>\n",
       "      <td>0.001180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6075010300</td>\n",
       "      <td>0.001254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6075010400</td>\n",
       "      <td>0.001252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6075010400</td>\n",
       "      <td>0.001267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Geoid  prediction\n",
       "0  6075010200    0.001116\n",
       "1  6075010300    0.001180\n",
       "2  6075010300    0.001254\n",
       "3  6075010400    0.001252\n",
       "4  6075010400    0.001267"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_X_future_selected = normalize_columns(selected_features_future, X_ltrain, X_ltrain)\n",
    "normal_knn_y_future_pred = kn_regressor.predict(normal_X_future_selected)\n",
    "knn_y_future_pred = unnormalize_columns(normal_knn_y_future_pred, y_ltrain, y_ltrain)\n",
    "knn_prediction = pd.DataFrame(test_features_df[\"Geoid\"], columns=[\"Geoid\"])\n",
    "knn_prediction['prediction'] = knn_y_future_pred\n",
    "knn_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geoid</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6075010200</td>\n",
       "      <td>0.00126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6075010300</td>\n",
       "      <td>0.00126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6075010300</td>\n",
       "      <td>0.00126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6075010400</td>\n",
       "      <td>0.00126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6075010400</td>\n",
       "      <td>0.00126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Geoid  prediction\n",
       "0  6075010200     0.00126\n",
       "1  6075010300     0.00126\n",
       "2  6075010300     0.00126\n",
       "3  6075010400     0.00126\n",
       "4  6075010400     0.00126"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_rf_y_future_pred = rf_tree.predict(normal_X_future_selected)\n",
    "rf_y_future_pred = unnormalize_columns(normal_rf_y_future_pred, y_ltrain, y_ltrain)\n",
    "rf_prediction = pd.DataFrame(test_features_df[\"Geoid\"], columns=[\"Geoid\"])\n",
    "rf_prediction['prediction'] = rf_y_future_pred\n",
    "rf_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geoid</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6075010200</td>\n",
       "      <td>0.000757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6075010300</td>\n",
       "      <td>0.000963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6075010300</td>\n",
       "      <td>0.001376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6075010400</td>\n",
       "      <td>0.001098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6075010400</td>\n",
       "      <td>0.001514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Geoid  prediction\n",
       "0  6075010200    0.000757\n",
       "1  6075010300    0.000963\n",
       "2  6075010300    0.001376\n",
       "3  6075010400    0.001098\n",
       "4  6075010400    0.001514"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_ridge_y_future_pred = ridge_alpha.predict(normal_X_future_selected)\n",
    "ridge_y_future_pred = unnormalize_columns(normal_ridge_y_future_pred, y_ltrain, y_ltrain)\n",
    "ridge_prediction = pd.DataFrame(test_features_df[\"Geoid\"], columns=[\"Geoid\"])\n",
    "ridge_prediction['prediction'] = ridge_y_future_pred\n",
    "ridge_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geoid</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6075010200</td>\n",
       "      <td>0.000968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6075010300</td>\n",
       "      <td>0.001103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6075010300</td>\n",
       "      <td>0.001504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6075010400</td>\n",
       "      <td>0.001601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6075010400</td>\n",
       "      <td>0.001966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Geoid  prediction\n",
       "0  6075010200    0.000968\n",
       "1  6075010300    0.001103\n",
       "2  6075010300    0.001504\n",
       "3  6075010400    0.001601\n",
       "4  6075010400    0.001966"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_nn_y_future_pred = model.predict(normal_X_future_selected)\n",
    "nn_y_future_pred = unnormalize_columns(normal_nn_y_future_pred, y_ltrain, y_ltrain)\n",
    "nn_prediction = pd.DataFrame(test_features_df[\"Geoid\"], columns=[\"Geoid\"])\n",
    "nn_prediction['prediction'] = nn_y_future_pred\n",
    "nn_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
